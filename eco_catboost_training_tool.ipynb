{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 300\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "from src.web.train_util import read_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Variables.\n",
    "Variables that are defined in this cell can be injected and overwritten by the machine learning platform.\n",
    "'''\n",
    "\n",
    "'''\n",
    "MLP defined variables\n",
    "'''\n",
    "training_runner = None\n",
    "project_id = None\n",
    "training_id = None\n",
    "metrics_feedback_url = None\n",
    "model_file = None\n",
    "output_dir = 'out'\n",
    "training_metrics_file = 'training.metrics'\n",
    "cross_validation_metrics_file = 'cross_validation.metrics'\n",
    "testing_metrics_file = 'testing.metrics'\n",
    "feature_importance_file = \"feature.importance\"\n",
    "\n",
    "\n",
    "'''\n",
    "feature variables\n",
    "'''\n",
    "input_features = {\n",
    "    \"billing_country\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"bin\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"card_brand\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"card_category\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"card_class\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"card_usage\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"cc_expiration_date\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"day_of_month\": {\n",
    "        \"type\": \"integer\"\n",
    "    },\n",
    "    \"funding_source\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"issuer_country\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"payment_amount_usd\": {\n",
    "        \"type\": \"number\"\n",
    "    },\n",
    "    \"payment_currency\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"payment_method_id\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"transaction_date_in_string\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"bank_name\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"renew_att_num\": {\n",
    "        \"type\": \"integer\"\n",
    "    }\n",
    "}\n",
    "\n",
    "features_cat = [\n",
    "    \"card_category\",\n",
    "    \"issuer_country\",\n",
    "    \"day_of_month\",\n",
    "    \"bin\",\n",
    "    \"payment_currency\",\n",
    "    \"renew_att_num\"\n",
    "]\n",
    "\n",
    "features_float = [\n",
    "    'bin',\n",
    "    'date_increment'\n",
    "]\n",
    "\n",
    "features_num = []\n",
    "features_num_calculated = []\n",
    "features_num_encoded = ['added_expiry_years']   \n",
    "features_num_bin_profile = []\n",
    "\n",
    "features_cat_encoded = ['day_of_week', 'cc_month']\n",
    "\n",
    "features_grouped = [['added_expiry_years', 'bin'], ['date_increment', 'bin']]\n",
    "\n",
    "additional_fields = [\n",
    "    'transaction_date_in_string',\n",
    "    'cc_expiration_date',\n",
    "    'billing_country',\n",
    "    'date_increment',\n",
    "    'added_expiry_years'\n",
    "]\n",
    "\n",
    "feature_candidates = [\n",
    "    \"card_brand\",\n",
    "    \"funding_source\",\n",
    "    \"card_category\",\n",
    "    \"card_class\",\n",
    "    \"card_usage\",\n",
    "    \"issuer_country\",\n",
    "    \"day_of_month\",\n",
    "    \"payment_method_id\",\n",
    "    \"bin\",\n",
    "    \"payment_currency\",\n",
    "    \"date_increment\",\n",
    "    \"bank_name\",\n",
    "    \"merchant_number\",\n",
    "    \"payment_service_id\",\n",
    "    \"added_expiry_years\",\n",
    "    'renew_att_num'\n",
    "]\n",
    "\n",
    "usecols = feature_candidates +  \n",
    "        ['response_message', \n",
    "         'subscription_id', \n",
    "         'success', \n",
    "         'cid' ,\n",
    "         'bank_name',\n",
    "         'added_expiry_years', \n",
    "         'received_date', \n",
    "         'billing_country', \n",
    "         'transaction_date_in_string', \n",
    "         'cc_expiration_date']\n",
    "\n",
    "\n",
    "'''\n",
    "data variables\n",
    "'''\n",
    "excluded_processors = ['mes', 'paypalExpress']\n",
    "excluded_decline_types = [\n",
    "    'unable to determine format',\n",
    "    'attempt_lower_amount',\n",
    "    'Stop Recurring',\n",
    "    'no reply',\n",
    "    'litle http response code',\n",
    "    'ioexception',\n",
    "    'invalid merchant',\n",
    "    'issuer unavailable',\n",
    "    'no charge model found',\n",
    "    'corrupt input data to server',\n",
    "    'Insufficient Funds'\n",
    "]\n",
    "\n",
    "\n",
    "#'dca_2019_06.csv', 'dca_2019_07.csv', 'dca_2019_08.csv', 'dca_2019_09.csv','dca_2019_10.csv'\n",
    "# TO DO : dca_2019_11\n",
    "training_files = ['eco_all_2019_01_to_03.csv', 'eco_2019_04_to_05.csv', 'eco_2019_06.csv', 'eco_2019_07.csv']\n",
    "\n",
    "eval_files = [ 'eco_2019_08.csv']\n",
    "test_files = [ 'eco_2019_09.csv']\n",
    "\n",
    "\n",
    "'''\n",
    "hyperparameters variables\n",
    "'''\n",
    "scale_pos_weight = None\n",
    "\n",
    "tuned_parameters = {}\n",
    "\n",
    "best_parameters = {\n",
    "    'depth': 6,\n",
    "    'iterations': 1501,\n",
    "    'random_seed': 8,\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "    'subsample': 0.6,\n",
    "    'bagging_temperature': 3.0,\n",
    "    'rsm': 0.35,\n",
    "    'eval_metric': 'BrierScore',\n",
    "    'early_stopping_rounds': 500,\n",
    "    'l2_leaf_reg': 37.7,\n",
    "    'model_size_reg': 6.0,\n",
    "    'random_strength': 3.0,\n",
    "    'best_model_min_trees': 700\n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "other variables\n",
    "'''\n",
    "label = 'success'\n",
    "work_dir = '/var/spark/ml_files/'\n",
    "model_type = 'ML-ECO'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2020-01-31'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Variable manipulation after variable injection\n",
    "'''\n",
    "\n",
    "features_encoded = features_cat_encoded + features_num_encoded\n",
    "\n",
    "usecols = feature_candidates + usecols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decline_type(response_msg):\n",
    "#     \"\"\"Converts to decline_type based on the given response_msg\"\"\"\n",
    "#     dec_type = df_decline_type[df_decline_type['DECLINE_TEXT'] == response_msg]['DECLINE_TYPE']\n",
    "#     if dec_type.empty or dec_type.iloc[0] == 'Base' :\n",
    "#         return group_response_msg(response_msg)\n",
    "#     else:\n",
    "#         return dec_type.iloc[0]\n",
    "    \n",
    "msg_group = { 'declined' : 'decline', \n",
    "             'do_not_honor' : 'do not honor', \n",
    "             'txn_refused' : 'refuse', \n",
    "             'attempt_lower_amount' : 'lower amount',\n",
    "            'Insufficient Funds' : 'insufficient',\n",
    "            'not_allowed' : 'not allowed',\n",
    "            'correct_cc_retry' : 'correct card',\n",
    "            'invalid_cc' : 'invalid card',\n",
    "            'lost_stolen' : 'lost or stolen',\n",
    "            'invalid_account' : 'invalid account',\n",
    "            'do_not_try' : 'do not try',\n",
    "            'expired_card' : 'expired',\n",
    "            'pickup_card' : 'pick',\n",
    "            'blocked_first_used' : 'blocked',\n",
    "            'invalid_txn' : 'invalid trans',\n",
    "            'restricted_card' : 'restricted',\n",
    "            'not_permitted' : 'not permitted',\n",
    "            'expired card' : 'expired card',\n",
    "            'unable to determine format' : 'determine format',\n",
    "            'system error' : 'error',\n",
    "            'no reply' : 'no reply',\n",
    "             'no charge model found' : 'no charge model found',\n",
    "             'issuer unavailable' : 'issuer unavailable',\n",
    "             'litle http response code' : 'litle http response code',\n",
    "             'corrupt input data to server' : 'corrupt input data to server',\n",
    "             'ioexception' : 'ioexception',\n",
    "             'invalid merchant' : 'invalid merchant',\n",
    "            }\n",
    "\n",
    "def group_response_msg(msg):\n",
    "    other = 'Base'\n",
    "    if isinstance(msg, str) == False:\n",
    "        return other\n",
    "    \n",
    "    msg_lower = msg.lower()\n",
    "    for key, val in msg_group.items():\n",
    "        if val in msg_lower:\n",
    "            return key\n",
    "        \n",
    "    return other   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_decline_type = read_from(decline_type_file, s3_dir='ml_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_eco(eco):\n",
    "    eco[~(eco['payment_service_id'].isin(excluded_processors))]\n",
    "    eco.loc[eco.added_expiry_years == 'STALE', 'date_increment'] = 0\n",
    "    eco.loc[eco.added_expiry_years == 'STALE', 'added_expiry_years'] = 0\n",
    "\n",
    "    eco.loc[eco.added_expiry_years == 'ADD_YEARS', 'added_expiry_years'] = eco['date_increment']\n",
    "\n",
    "    eco['date_increment'] = eco['date_increment'].apply(str).str.replace('.0', '', regex=False)\n",
    "    eco['added_expiry_years'] = eco['added_expiry_years'].apply(str).str.replace('.0', '', regex=False)\n",
    "    eco['cc_expiration_date'] = eco['cc_expiration_date'].apply(str)\n",
    "    eco.loc[eco['date_increment'] == 'nan', 'date_increment'] = eco['added_expiry_years']\n",
    "    \n",
    "#     eco['decline_type'] = eco['response_message'].apply(decline_type)\n",
    "#     eco = eco[~eco['decline_type'].isin(excluded_decline_types)]\n",
    "    return eco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat((read_from(file, usecols=usecols, s3_dir='training_files') for file in training_files) , ignore_index=True)\n",
    "df_train = process_eco(df_train)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.concat((read_from(file, usecols=usecols, s3_dir='training_files') for file in eval_files) , ignore_index=True)\n",
    "df_eval = process_eco(df_eval)\n",
    "df_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat((read_from(file, usecols=usecols, s3_dir='training_files') for file in test_files) , ignore_index=True)\n",
    "df_test = process_eco(df_test)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = len(df_train)\n",
    "balanced_size = len(df_train)\n",
    "fail_size = df_train[label].value_counts(normalize=True)[0.0]\n",
    "success_size =  df_train[label].value_counts(normalize=True)[1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional_fields = ['card_brand',  'segment_num', 'segment_num_group' ,'bank_name', 'duration', 'is_expired', 'renewal_window', 'payment_currency', 'funding_source', 'card_category', 'card_class', 'card_usage', 'renew_att_num', 'site_id', 'bin', 'merchant_number', 'billing_country', 'funding_source', \"payment_service_id\", 'day_of_month', 'failed_decline_type',  'failed_day_of_month', 'failed_response_code', 'payment_amount_usd', 'issuer_country',  'failed_response_message','days_between',  'transaction_date_in_string', 'cc_expiration_date', 'failed_attempt_date']\n",
    "additional_fields = [x for x in additional_fields if x not in (features_cat+features_num)]\n",
    "fields = features_cat + features_num + additional_fields\n",
    "\n",
    "\n",
    "# df_decline_type = read_from('Decline_Type.csv')\n",
    "\n",
    "features_dict = {'LABEL': label, 'FIELDS': fields ,'FEATURES_CAT': features_cat, 'FEATURES_NUM':features_num, 'FEATURES_ENCODED':features_encoded, 'FEATURES_NUM_ENCODED':features_num_encoded, 'FEATURES_NUM_CALCULATED':features_num_calculated, 'FEATURES_FLOAT': features_float}\n",
    "features_dict_key = 'preprocessing__features_dict'\n",
    "\n",
    "features_dict['FEATURES_GROUPED'] = features_grouped\n",
    "features_dict['ADDITIONAL_FIELDS'] = additional_fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Prepares training parameters'''\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from src.web.train_util import *\n",
    "\n",
    "classifier = CatBoostClassifier\n",
    "\n",
    "cat_features_len = len(features_cat) +  len (features_grouped)\n",
    "input_data = df_train\n",
    "\n",
    "features_dict['use_cat_encoder'] = False\n",
    "_preProcessor = PreProcessing().fit(input_data, input_data['success'], features_dict=features_dict)\n",
    "\n",
    "_df_val = df_eval\n",
    "_df_test = df_test\n",
    "scale_pos_weight = (_df_val[label].value_counts(normalize=True)[0.0] / _df_val[label].value_counts(normalize=True)[1.0] )\n",
    "best_parameters['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "_x_eval = _preProcessor.transform(_df_val)\n",
    "_y_eval = _df_val[\"success\"]\n",
    "\n",
    "\n",
    "alg_name = 'catboostclassifier'\n",
    "\n",
    "\n",
    "cat_features = list(range(0,cat_features_len))\n",
    "\n",
    "fit_params = {\n",
    "    f\"{alg_name}__verbose\": True,\n",
    "    f\"{alg_name}__cat_features\": cat_features,\n",
    "    f\"{alg_name}__plot\": True,\n",
    "    f\"{alg_name}__eval_set\": Pool(_x_eval, _y_eval, cat_features)\n",
    "}\n",
    "\n",
    "\n",
    "features_dict['fit_params'] = fit_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train the model\"\"\"\n",
    "\n",
    "clf, result_d = build_and_train(\n",
    "    input_data[:100], \n",
    "    classifier, \n",
    "    tuned_parameters, \n",
    "    alg_name, \n",
    "    model_file, \n",
    "    best_param=best_parameters, \n",
    "    features_dict=features_dict, \n",
    "    test_data=_df_test,\n",
    "    output_dir=output_dir)\n",
    "                                   \n",
    "print(\"result_dict: \", result_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "output the model\n",
    "'''\n",
    "\n",
    "if training_runner is None:\n",
    "    model_id = 'ML-ECO-Test-1'\n",
    "    version = get_latest_version(model_id, model_type) + 1\n",
    "    model_name = model_id + '.' + str(version)\n",
    "    model_file, model_file_name = write_model(clf, model_name)\n",
    "    \n",
    "    preprocess_repo_path = handle_preprocessing_file(model_id, version)\n",
    "    size_desc = str(\", original size: %s (fail: %s, success: %s), balanced_size: %s\" % (original_size, fail_size, success_size, original_size))\n",
    "    desc = 'Using more specific failed_decline_type. Assign scale_pos_weight. Remove site_id.  Remove days_between-card_brand and funding_source. Add days_between-failed_decline_code. Include data with null first_cal_attempt. Add bank_name-is_expired, handle card_brand to be lower when grouping. Remove days_between_first_cal. With days_between-card_brand, reduce model_size_reg. Handle sub_duration_group in preprocessing. Minus segment_num. Using updated bank_profile, bin_profile to end of March. Use duration, sub_age, segment_num as numeric. Update sub_duration_group, days_between-card_brand,  duration(handle 28, 29,31 366 and 731), card_brand, renew_att_num,  sub_age.  Add days_between-failed_decline_type.  bank_card_max_per_date.  Add issuer_country-is_expired and bin-is_expired .is_expired to be True for all non na date increment. More individual features. Add more specific failed_decline_type. 2020_03 as val data and 2020_04 as test data  {}_{}_for_calendar retry model,  eval_metric= BrierScore, with no date_increment, no payment amount and bin profile). {}'.format(start_date, end_date, size_desc)\n",
    "\n",
    "    hyper_params = result_d.pop('hyper_params', None)\n",
    "    extended_att = {\"preprocess_repo_path\": preprocess_repo_path, \"input_features\": input_features}\n",
    "    repo_path = upload_artifact(model_file_name)\n",
    "    insert_model_info(model_id, version, repo_path, desc=desc, model_type=model_type,eval_metrics=json.dumps(result_d), \n",
    "                      hyper_parameter=json.dumps(hyper_params), extended_att=json.dumps(extended_att), features_dict=features_dict, algorithm='CatBoostClassifier')\n",
    "    \n",
    "else:\n",
    "    model_file = joblib.dump(clf, model_file)\n",
    "\n",
    "print('model_file generated: ', model_file)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
