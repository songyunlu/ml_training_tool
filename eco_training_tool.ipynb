{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies\n",
        "Install **anaconda** is recommended\n",
        "\n",
        "| Name             | Version | Numpy & Python Version   |             |\n",
        "| ---------------- |---------|--------------------------|-------------|\n",
        "| cassandra-driver | 3.11.0  |      py35_1              | conda-forge |\n",
        "| pandas           | 0.19.1  | np111py35_0              |             | \n",
        "| scikit-learn     | 0.18.1  | np111py35_0              |             |\n",
        "| scipy            | 0.18.1  | np111py35_0              |             |\n",
        "| matplotlib       | 2.0.0   | np111py35_0              |             |"
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "commands.\n",
        "'''\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Parameters. \n",
        "Parameters that are defined in this cell can be injected and overwritten by the machine learning platform.\n",
        "'''\n",
        "\n",
        "# MLP defined parameters \n",
        "training_runner = None\n",
        "project_id = None\n",
        "training_id = None\n",
        "metrics_feedback_url = None\n",
        "model_destination = None\n",
        "\n",
        "# user defined parameters\n",
        "\n",
        "# label keys\n",
        "label = 'success'\n",
        "# model file directory\n",
        "work_dir = '/var/spark/ml_files/'\n",
        "model_type = 'ML-ECO'\n",
        "start_date = '2018-01-01'\n",
        "end_date = '2019-05-31'\n",
        "# desc = '%s_%s_for_calendar_retry_attempt'.format(start_date, end_date)\n",
        "\n",
        "# data\n",
        "training_data = work_dir + 'eco_2019_06.csv'\n",
        "date_increment_bin_data =  work_dir + 'date_increment_bin_2019_Q1.csv'\n",
        "added_years_bin_data = work_dir + 'added_years_bin_2019_Q1.csv'\n",
        "\n",
        "# features\n",
        "input_features = {\n",
        "    'billing_country': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'bin': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'card_brand': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'card_category': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'card_class': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'card_usage': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'cc_expiration_date': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'day_of_month': {\n",
        "        'type': 'integer'\n",
        "    },\n",
        "    'funding_source': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'issuer_country': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'payment_amount_usd': {\n",
        "        'type': 'number'\n",
        "    },\n",
        "    'payment_currency': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'payment_method_id': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'transaction_date_in_string': {\n",
        "        'type': 'string'\n",
        "    },\n",
        "    'bank_name': {\n",
        "        'type': 'string'\n",
        "    }\n",
        "}\n",
        "features_cat = [\n",
        "    'card_brand', \n",
        "    'funding_source', \n",
        "    'card_category', \n",
        "    'card_class', \n",
        "    'card_usage', \n",
        "    'issuer_country', \n",
        "    'day_of_month', \n",
        "    'payment_method_id', \n",
        "    'bin',  \n",
        "    'payment_currency', \n",
        "    'date_increment', \n",
        "    'bank_name', \n",
        "    'merchant_number', \n",
        "    'payment_service_id'\n",
        "]\n",
        "features_float = [\n",
        "    'bin', \n",
        "    'date_increment'\n",
        "]\n",
        "features_num = []\n",
        "features_num_calculated = [] \n",
        "features_num_encoded = [\n",
        "    'expired_years_diff', \n",
        "    'years_over', \n",
        "    'date_inc_bin', \n",
        "    'add_expiry_years_bin'\n",
        "]\n",
        "features_encoded = [\n",
        "    'week_of_month', \n",
        "    'day_of_week', \n",
        "    'month', \n",
        "    'cc_month', \n",
        "    'is_expired'\n",
        "]\n",
        "\n",
        "# hyperparameters\n",
        "tuned_parameters = None\n",
        "best_parameters = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'learning_rate': 0.13, #so called `eta` value\n",
        "    'max_depth': 10,\n",
        "    'min_child_weight': 6,\n",
        "    'silent': 0,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'n_estimators': 1000,\n",
        "    'missing':-999,\n",
        "    'seed': 1337,\n",
        "    'scale_pos_weight': 1,\n",
        "    'eval_metric': 'map',\n",
        "    'gamma': 2  \n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "print out all parameters.\n",
        "'''\n",
        "\n",
        "print('training_runner', training_runner)\n",
        "print('project_id =', project_id)\n",
        "print('training_id =', training_id)\n",
        "print('metrics_feedback_url =', metrics_feedback_url)\n",
        "print('model_destination =', model_destination)\n",
        "print('label =', label)\n",
        "print('training_data =', training_data)\n",
        "print('data_increment_bin_data =', date_increment_bin_data)\n",
        "print('added_years_bin_data =', added_years_bin_data)\n",
        "print('input_features =', input_features)\n",
        "print('features_cat =', features_cat)\n",
        "print('features_float =', features_float)\n",
        "print('features_num =', features_num)\n",
        "print('features_num_calculated = ', features_num_calculated)\n",
        "print('features_num_encoded = ', features_num_encoded)\n",
        "print('features_encoded =', features_encoded)\n",
        "print('tuned_parameters =', tuned_parameters)\n",
        "print('best_parameters =', best_parameters)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "imports.\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "if training_runner is None:\n",
        "    # from cassandra\n",
        "    from cassandra.cluster import Cluster\n",
        "    cassandra_endpoint = '10.62.1.118'\n",
        "    cluster = Cluster([cassandra_endpoint])\n",
        "    \n",
        "# import for training\n",
        "import numpy as np\n",
        "from sklearn import cross_validation\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import tree\n",
        "from sklearn import cross_validation\n",
        "from sklearn import ensemble\n",
        "from sklearn import linear_model\n",
        "from sklearn import svm\n",
        "from sklearn.dummy import DummyClassifier\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "from spark_sklearn import GridSearchCV\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# from src.web.utils import PreProcessing\n",
        "from src.web.preprocessing import PreProcessing\n",
        "from src.web.preprocessing import make_pipeline\n",
        "from sklearn.preprocessing import Imputer\n",
        "from src.web.encoder import EnhancedLeaveOneOutEncoder\n",
        "from src.web.train_util import *\n",
        "from xgboost import XGBClassifier\n",
        "from src.web.train_util import *\n",
        "from sklearn.externals import joblib"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "configurations.\n",
        "'''\n",
        "\n",
        "pd.options.display.max_colwidth = 300\n",
        "pd.options.display.max_columns = 100\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "training data manipulation.\n",
        "'''\n",
        "\n",
        "eco = pd.read_csv(training_data)\n",
        "eco.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "date increment bin data manipulation.\n",
        "'''\n",
        "\n",
        "date_increment_bin_dict = None\n",
        "\n",
        "if date_increment_bin_data:\n",
        "    date_increment_bin = pd.read_csv(date_increment_bin_data)\n",
        "    date_increment_bin.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "    date_increment_bin['bin'] = date_increment_bin['bin'].apply(str).str.replace('.0', '', regex=False)\n",
        "    date_increment_bin['date_increment'] = date_increment_bin['date_increment'].apply(str).str.replace('.0', '', regex=False)\n",
        "    date_increment_bin_dict = date_increment_bin.set_index(['bin', 'date_increment'])['success_rate'].T.to_dict()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "added years bin data manipulation.\n",
        "'''\n",
        "\n",
        "added_years_bin_dict = None\n",
        "if added_years_bin_data:\n",
        "    added_years_bin = pd.read_csv(added_years_bin_data)\n",
        "    added_years_bin.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "    added_years_bin['bin'] = added_years_bin['bin'].apply(str).str.replace('.0', '', regex=False)\n",
        "    added_years_bin['added_expiry_years'] = added_years_bin['added_expiry_years'].apply(str).str.replace('.0', '', regex=False)\n",
        "    added_years_bin_dict = added_years_bin.set_index(['bin', 'added_expiry_years'])['success_rate'].T.to_dict()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "eco = eco[~eco['date_increment'].isna()]\n",
        "eco = eco[~eco['added_expiry_years'].isna()]\n",
        "# eco.loc[eco.added_expiry_years == 'STALE', 'added_expiry_years'] = 0\n",
        "eco['cc_expiration_date'] = eco['cc_expiration_date'].apply(str)\n",
        "eco.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "original_size = len(eco)\n",
        "fail_size = eco[label].value_counts(normalize=True)[0.0]\n",
        "success_size =  eco[label].value_counts(normalize=True)[1.0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "feature manipulation and aggregation.\n",
        "'''\n",
        "\n",
        "features_encoded = features_encoded + features_num_calculated\n",
        "features = features_cat + features_encoded\n",
        "\n",
        "# fields = features_cat + features_num + ['transaction_date_in_string', 'cc_expiration_date', 'failed_attempt_date', 'failed_cc_expiration_date'] + features_num_encoded + features_num_calculated\n",
        "# fields = features_cat + features_num + ['transaction_date_in_string', 'cc_expiration_date', 'billing_country'] + features_num_encoded + features_num_calculated\n",
        "fields = features_cat + features_num + ['transaction_date_in_string', 'cc_expiration_date', 'billing_country']\n",
        "\n",
        "# df_decline_type = pd.read_csv(work_dir + 'Decline_Type.csv')\n",
        "\n",
        "features_dict = {\n",
        "    'LABEL': label, \n",
        "    'FIELDS': fields ,\n",
        "    'FEATURES_CAT': features_cat, \n",
        "    'FEATURES_NUM': features_num, \n",
        "    'FEATURES_ENCODED': features_encoded, \n",
        "    'FEATURES_NUM_ENCODED': features_num_encoded, \n",
        "    'FEATURES_NUM_CALCULATED': features_num_calculated, \n",
        "    'FEATURES_FLOAT': features_float\n",
        "}\n",
        "features_dict_key = 'preprocessing__features_dict'\n",
        "features_dict['df_bin_profile'] = None\n",
        "# features_dict['df_decline_type'] = df_decline_type\n",
        "# features_dict['df_eco_bin'] = eco_bin_profile\n",
        "\n",
        "features_dict['date_increment_bin_dict'] = date_increment_bin_dict\n",
        "features_dict['added_years_bin_dict'] = added_years_bin_dict"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "train the model with xgboost classifier.\n",
        "'''\n",
        "\n",
        "classifier = XGBClassifier\n",
        "scale_pos_weight = fail_size / success_size\n",
        "best_parameters['scale_pos_weight'] = scale_pos_weight\n",
        "\n",
        "model_file = ''\n",
        "features_dict['eval_metric'] = 'map'\n",
        "xgb_clf, result_d = build_and_train(\n",
        "    eco, \n",
        "    classifier, \n",
        "    tuned_parameters, \n",
        "    'xgbclassifier', \n",
        "    model_file, \n",
        "    best_param=best_parameters, \n",
        "    features_dict=features_dict\n",
        ")\n",
        "print('result_dict: ', result_d)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "output the model\n",
        "'''\n",
        "\n",
        "if training_runner is None:\n",
        "    from src.web.model_info_repository import get_latest_version\n",
        "    model_id = 'ML-ECO-2'\n",
        "    version = get_latest_version(model_id, model_type) + 1\n",
        "    model_name = model_id + '.' + str(version)\n",
        "    model_file, model_file_name = write_model(xgb_clf, model_name)\n",
        "else:\n",
        "    model_file = joblib.dump(xgb_clf, model_destination)\n",
        "\n",
        "print('model_file generated: ', model_file)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"Upload model to Nexus repo and insert the model info into Cassandra table\"\"\"\n",
        "# import json\n",
        "\n",
        "# # start_date = '2018-01-01'\n",
        "# start_date = '2019-01-01'\n",
        "\n",
        "# end_date = '2019-05-31'\n",
        "\n",
        "# try:\n",
        "#     repo_path = upload_artifact(model_file_name)\n",
        "#     preprocess_repo_path = handle_preprocessing_file(model_id, version)\n",
        "#     size_desc = str(\", original size: %s (fail: %s, success: %s), balanced_size: %s\" % (original_size, fail_size, success_size, original_size))\n",
        "#     desc = '{}_{}_for_eco model with date_inc_bin and added_years_bin. {}'.format(start_date, end_date, size_desc)\n",
        "#     hyper_params = result_d.pop('hyper_params', None)\n",
        "#     extended_att = {\"preprocess_repo_path\": preprocess_repo_path, \"input_features\": INPUT_FEATURES}\n",
        "#     insert_model_info(model_id, version, repo_path, desc=desc, model_type=MODEL_TYPE,eval_metrics=json.dumps(result_d), \n",
        "#                       hyper_parameter=json.dumps(hyper_params), extended_att=json.dumps(extended_att), features_dict=features_dict)\n",
        "    \n",
        "# except:\n",
        "#     if not hyper_params:\n",
        "#         result_d['hyper_params'] = hyper_params "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}