{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dependencies\n",
    "Install **anaconda** is recommended\n",
    "\n",
    "| Name             | Version | Numpy & Python Version   |             |\n",
    "| ---------------- |---------|--------------------------|-------------|\n",
    "| cassandra-driver | 3.11.0  |      py35_1              | conda-forge |\n",
    "| pandas           | 0.19.1  | np111py35_0              |             | \n",
    "| scikit-learn     | 0.18.1  | np111py35_0              |             |\n",
    "| scipy            | 0.18.1  | np111py35_0              |             |\n",
    "| matplotlib       | 2.0.0   | np111py35_0              |             |"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "commands.\n",
    "'''\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Parameters. \n",
    "Parameters that are defined in this cell can be injected and overwritten by the machine learning platform.\n",
    "'''\n",
    "\n",
    "# MLP defined parameters \n",
    "training_runner = None\n",
    "project_id = None\n",
    "training_id = None\n",
    "metrics_feedback_url = None\n",
    "model_file = None\n",
    "output_dir = 'out'\n",
    "training_metrics_file = 'training.metrics'\n",
    "cross_validation_metrics_file = 'cross_validation.metrics'\n",
    "testing_metrics_file = 'testing.metrics'\n",
    "\n",
    "# user defined parameters\n",
    "\n",
    "# label keys\n",
    "label = 'success'\n",
    "# model file directory\n",
    "work_dir = '/var/spark/ml_files/'\n",
    "model_type = 'ML-BR'\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2019-05-31'\n",
    "# desc = '%s_%s_for_calendar_retry_attempt'.format(start_date, end_date)\n",
    "\n",
    "# data\n",
    "training_data = work_dir + 'calendar_retry_2019_04.csv'\n",
    "bin_profile_data =  work_dir + 'bin_profile_2019_01_to_2019_05.csv'\n",
    "payment_mid_bin_data = work_dir + 'payment_mid_bin_2019_01_to_05.csv'\n",
    "decline_type_data = work_dir + 'Decline_Type.csv'\n",
    "\n",
    "# features\n",
    "input_features = {\n",
    "    'billing_country': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'bin': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'card_brand': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'card_category': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'card_class': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'card_usage': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'cc_expiration_date': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'day_of_month': {\n",
    "        'type': 'integer'\n",
    "    },\n",
    "    'failed_attempt_date': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'failed_response_code': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'failed_response_message': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'funding_source': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'issuer_country': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'merchant_number': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'payment_amount_usd': {\n",
    "        'type': 'number'\n",
    "    },\n",
    "    'payment_currency': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'payment_method_id': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'payment_service_id': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'renew_att_num': {\n",
    "        'type': 'integer'\n",
    "    },\n",
    "    'site_id': {\n",
    "        'type': 'string'\n",
    "    },\n",
    "    'transaction_date_in_string': {\n",
    "        'type': 'string'\n",
    "    }\n",
    "}\n",
    "features_cat = [\n",
    "    'card_brand', \n",
    "    'funding_source', \n",
    "    'card_category', \n",
    "    'card_class', \n",
    "    'card_usage', \n",
    "    'issuer_country', \n",
    "    'day_of_month', \n",
    "    'site_id', \n",
    "    'failed_decline_type', \n",
    "    'merchant_number', \n",
    "    'payment_service_id', \n",
    "    'payment_method_id', \n",
    "    'bin', \n",
    "    'renew_att_num', \n",
    "    'failed_day_of_month', \n",
    "    'payment_currency', \n",
    "    'days_between',\n",
    "    'failed_response_code'\n",
    "]\n",
    "features_float = [ \n",
    "    'bin', \n",
    "    'renew_att_num', \n",
    "    'failed_response_code' \n",
    "]\n",
    "features_num = [ \n",
    "    'payment_amount_usd' \n",
    "]\n",
    "features_encoded = [ \n",
    "    'week_of_month', \n",
    "    'day_of_week', \n",
    "    'is_expired'\n",
    "]\n",
    "features_num_bin_profile = [ \n",
    "    'Mean', \n",
    "    'Median', \n",
    "    'StdDev', \n",
    "    'Max_99', \n",
    "    'Max' \n",
    "]\n",
    "\n",
    "# hyperparameters\n",
    "tuned_parameters = {\n",
    "    'objective':['binary:logistic'],\n",
    "    'learning_rate': [0.2], #so called `eta` value\n",
    "    'max_depth': [10],\n",
    "    'min_child_weight': [11],\n",
    "    'silent': [0],\n",
    "    'subsample': [0.5],\n",
    "    'colsample_bytree': [0.7],\n",
    "#    'n_estimators': [500, 1000], #number of trees, change it to 1000 for better results\n",
    "    'n_estimators': [1000], #number of trees, change it to 1000 for better results  \n",
    "    'missing':[-999],\n",
    "    'max_delta_step':[1],  \n",
    "    'seed': [1337]\n",
    "}\n",
    "\n",
    "best_parameters = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.15, #so called `eta` value\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 8,\n",
    "    'silent': 0,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "#     'n_estimators': [500, 1000], #number of trees, change it to 1000 for better results\n",
    "    'n_estimators': 1000, #number of trees, change it to 1000 for better results  \n",
    "    'missing':-999,\n",
    "    'seed': 1337,\n",
    "    'scale_pos_weight': 1,\n",
    "    'gamma': 1\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "print out all parameters.\n",
    "'''\n",
    "\n",
    "print('training_runner = ', training_runner)\n",
    "print('project_id =', project_id)\n",
    "print('training_id =', training_id)\n",
    "print('metrics_feedback_url =', metrics_feedback_url)\n",
    "print('training_metrics_file =', training_metrics_file)\n",
    "print('cross_validation_metrics_file =', cross_validation_metrics_file)\n",
    "print('testing_metrics_file =', testing_metrics_file)\n",
    "print('model_file =', model_file)\n",
    "print('label =', label)\n",
    "print('training_data =', training_data)\n",
    "print('bin_profile_data =', bin_profile_data)\n",
    "print('payment_mid_bin_data =', payment_mid_bin_data)\n",
    "print('decline_type_data =', decline_type_data)\n",
    "print('input_features =', input_features)\n",
    "print('features_cat =', features_cat)\n",
    "print('features_float =', features_float)\n",
    "print('features_num =', features_num)\n",
    "print('features_num_bin_profile =', features_num_bin_profile)\n",
    "print('features_encoded =', features_encoded)\n",
    "print('tuned_parameters =', tuned_parameters)\n",
    "print('best_parameters =', best_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "imports.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "if training_runner is None:\n",
    "    # from cassandra\n",
    "    from cassandra.cluster import Cluster\n",
    "    cassandra_endpoint = '10.62.1.118'\n",
    "    cluster = Cluster([cassandra_endpoint])\n",
    "    \n",
    "#import for training\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import cross_validation\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.dummy import DummyClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from spark_sklearn import GridSearchCV\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from src.web.utils import PreProcessing\n",
    "from src.web.preprocessing import PreProcessing\n",
    "from src.web.encoder import EnhancedLeaveOneOutEncoder\n",
    "from src.web.train_util import *\n",
    "from xgboost import XGBClassifier\n",
    "from src.web.train_util import *\n",
    "from sklearn.externals import joblib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "configurations.\n",
    "'''\n",
    "pd.options.display.max_colwidth = 300\n",
    "pd.options.display.max_columns = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "training data manipulation.\n",
    "'''\n",
    "\n",
    "retry_success =  pd.read_csv(training_data)\n",
    "retry_success['bin'] = retry_success['bin'].fillna('').astype(str).str.replace('.0', '', regex=False)\n",
    "retry_success.shape\n",
    "retry_success.head()"
   ],
   "outputs": [],
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "bin profile data manipulation.\n",
    "'''\n",
    "\n",
    "bin_profile = None\n",
    "if bin_profile_data:\n",
    "    bin_profile = pd.read_csv(bin_profile_data)\n",
    "    bin_profile['bin'] = bin_profile['bin'].fillna('').astype(str).str.replace('.0', '', regex=False)\n",
    "    bin_profile.shape"
   ],
   "outputs": [],
   "execution_count": 27,
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "payment mid bin data manipulation.\n",
    "'''\n",
    "\n",
    "payment_mid_bin_dict = None\n",
    "if payment_mid_bin_data:\n",
    "    payment_mid_bin = pd.read_csv(payment_mid_bin_data)\n",
    "    payment_mid_bin['bin'] = payment_mid_bin['bin'].apply(str).str.replace('.0', '', regex=False)\n",
    "    payment_mid_bin_dict = payment_mid_bin.set_index(['bin', 'payment_service_id', 'merchant_number'])['success_rate'].T.to_dict()\n",
    "    payment_mid_bin_dict\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 31,
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "decline type data manipulation.\n",
    "'''\n",
    "\n",
    "df_decline_type = pd.read_csv(decline_type_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_size = len(retry_success)\n",
    "fail_size = retry_success[label].value_counts(normalize=True)[0.0]\n",
    "success_size =  retry_success[label].value_counts(normalize=True)[1.0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "feature manipulation and aggregation.\n",
    "'''\n",
    "\n",
    "features_num_encoded = [] + features_num_bin_profile  #, 'payment_mid_bin'\n",
    "features_encoded = features_encoded + features_num_encoded\n",
    "features_num_calculated = []\n",
    "features = features_cat + features_encoded\n",
    "\n",
    "fields = features_cat + \\\n",
    "         features_num + \\\n",
    "         ['transaction_date_in_string', 'cc_expiration_date', 'failed_attempt_date'] + \\\n",
    "         features_num_bin_profile\n",
    "\n",
    "features_dict = {\n",
    "    'LABEL': label, \n",
    "    'FIELDS': fields ,\n",
    "    'FEATURES_CAT': features_cat, \n",
    "    'FEATURES_NUM': features_num, \n",
    "    'FEATURES_ENCODED': features_encoded, \n",
    "    'FEATURES_NUM_ENCODED': features_num_encoded, \n",
    "    'FEATURES_NUM_CALCULATED': features_num_calculated, \n",
    "    'FEATURES_FLOAT': features_float\n",
    "}\n",
    "features_dict_key = 'preprocessing__features_dict'\n",
    "features_dict['df_bin_profile'] = bin_profile\n",
    "features_dict['df_decline_type'] = df_decline_type\n",
    "# features_dict['payment_mid_bin_dict'] = payment_mid_bin_dict\n",
    "features_dict['FEATURES_NUM_BIN_PROFILE'] = features_num_bin_profile"
   ],
   "outputs": [],
   "execution_count": 35,
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "print out manipulated and aggregated features.\n",
    "'''\n",
    "\n",
    "print('feature_num_encoded', features_encoded)\n",
    "print('features_encoded', features_encoded)\n",
    "print('features_num_calculated', features_num_calculated)\n",
    "print('features', features)\n",
    "print('fields', fields)\n",
    "print('features_dict', features_dict)\n",
    "print('features_dict_key', features_dict_key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "train the model with xgboost classifier\n",
    "'''\n",
    "\n",
    "classifier = XGBClassifier\n",
    "scale_pos_weight = fail_size / success_size\n",
    "best_parameters['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "features_dict['eval_metric'] = 'map'\n",
    "xgb_clf, result_d = build_and_train(\n",
    "    retry_success, \n",
    "    classifier, \n",
    "    tuned_parameters, \n",
    "    'xgbclassifier', \n",
    "    model_file, \n",
    "    best_param=best_parameters, \n",
    "    features_dict=features_dict,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "print('result_dict: ', result_d)"
   ],
   "outputs": [],
   "execution_count": 36,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "output the model\n",
    "'''\n",
    "\n",
    "if training_runner is None:\n",
    "    from src.web.model_info_repository import get_latest_version\n",
    "    model_id = 'ML-BR-1'\n",
    "    version = get_latest_version(model_id, model_type) + 1\n",
    "    model_name = model_id + '.' + str(version)\n",
    "    model_file, model_file_name = write_model(xgb_clf, model_name)\n",
    "else:\n",
    "    model_file = joblib.dump(xgb_clf, model_file)\n",
    "\n",
    "print('model_file generated: ', model_file)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# \"\"\"Upload model to Nexus repo and insert the model info into Cassandra table\"\"\"\n",
    "# import json\n",
    "\n",
    "# start_date = '2018-01-01'\n",
    "\n",
    "# end_date = '2019-05-31'\n",
    "\n",
    "# try:\n",
    "#     repo_path = upload_artifact(model_file_name)\n",
    "#     preprocess_repo_path = handle_preprocessing_file(model_id, version)\n",
    "#     size_desc = str(\", original size: %s (fail: %s, success: %s), balanced_size: %s\" % (original_size, fail_size, success_size, original_size))\n",
    "#     desc = '{}_{}_for_calendar retry model. {}'.format(start_date, end_date, size_desc)\n",
    "#     hyper_params = result_d.pop('hyper_params', None)\n",
    "#     extended_att = {\"preprocess_repo_path\": preprocess_repo_path, \"input_features\": INPUT_FEATURES}\n",
    "#     insert_model_info(model_id, version, repo_path, desc=desc, model_type=MODEL_TYPE,eval_metrics=json.dumps(result_d), \n",
    "#                       hyper_parameter=json.dumps(hyper_params), extended_att=json.dumps(extended_att), features_dict=features_dict)\n",
    "    \n",
    "# except:\n",
    "#     if not hyper_params:\n",
    "#         result_d['hyper_params'] = hyper_params "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernel_info": {
   "name": "python3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}