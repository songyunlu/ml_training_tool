{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# dependencies\n",
    "* install anaconda is recommended\n",
    "\n",
    "```\n",
    "cassandra-driver          3.11.0                   py35_1    conda-forge\n",
    "pandas                    0.19.1              np111py35_0\n",
    "scikit-learn              0.18.1              np111py35_0\n",
    "scipy                     0.18.1              np111py35_0\n",
    "matplotlib                2.0.0               np111py35_0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 300\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "from src.web.train_util import read_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters. \n",
    "Parameters that are defined in this cell can be injected and overwritten by the machine learning platform.\n",
    "'''\n",
    "\n",
    "# MLP defined parameters \n",
    "training_runner = None\n",
    "project_id = None\n",
    "training_id = None\n",
    "metrics_feedback_url = None\n",
    "model_destination = None\n",
    "\n",
    "# user defined parameters\n",
    "\n",
    "# label keys\n",
    "label = 'success'\n",
    "# model file directory\n",
    "work_dir = '/var/spark/ml_files/'\n",
    "model_type = 'ML-BR'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2020-01-31'\n",
    "# desc = '%s_%s_for_calendar_retry_attempt'.format(start_date, end_date)\n",
    "\n",
    "# data\n",
    "training_data = ''\n",
    "# bin_profile_data =  work_dir + 'bin_profile_2019_01_to_2019_05.csv'\n",
    "# payment_mid_bin_data = work_dir + 'payment_mid_bin_2019_01_to_05.csv'\n",
    "decline_type_data = work_dir + 'Decline_Type.csv'\n",
    "\n",
    "# features\n",
    "input_features = {\n",
    "            \"billing_country\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"bin\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"card_brand\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"card_category\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"card_class\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"card_usage\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"cc_expiration_date\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"day_of_month\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"failed_attempt_date\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"failed_response_code\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"failed_response_message\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"funding_source\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"issuer_country\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"merchant_number\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"payment_amount_usd\": {\n",
    "                \"type\": \"number\"\n",
    "            },\n",
    "            \"payment_currency\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"payment_method_id\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"payment_service_id\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"renew_att_num\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"site_id\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"transaction_date_in_string\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"renewal_window\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"duration\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"segment_num\": {\n",
    "                \"type\": \"integer\"\n",
    "            },\n",
    "            \"sub_age\": {\n",
    "                \"type\": \"integer\"\n",
    "            }, \n",
    "            \"bank_name\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"first_calendar_attempt_date\": {\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "features_cat = [ \n",
    "    'failed_response_code', \n",
    "    'failed_decline_type',  \n",
    "    'day_of_month', \n",
    "    'funding_source', \n",
    "    'payment_currency', \n",
    "    'days_between', \n",
    "    'billing_country', \n",
    "    'renewal_window',  \n",
    "    'renew_att_num', \n",
    "    'card_brand']\n",
    "\n",
    "features_float = [ \n",
    "    'bin',  \n",
    "    'failed_response_code', \n",
    "    'date_increment', \n",
    "    'renewal_window'\n",
    "]\n",
    "\n",
    "features_num = [ \n",
    "    'duration', \n",
    "    'sub_age'\n",
    "]\n",
    "features_num_calculated = []\n",
    "features_num_encoded = []   \n",
    "features_num_bin_profile = []\n",
    "\n",
    "features_cat_encoded = [\n",
    "    'month', \n",
    "    'days_between', \n",
    "    'renew_att_num', \n",
    "    'day_of_week', \n",
    "    'num_of_days', \n",
    "    'payment_service_id', \n",
    "    'merchant_number', \n",
    "    'month', \n",
    "    'is_expired', \n",
    "    'segment_num_group', \n",
    "    'sub_duration_group',  \n",
    "    'sub_age_group', \n",
    "    'card_brand'\n",
    "]\n",
    "\n",
    "\n",
    "features_grouped = [\n",
    "    ['payment_service_id', 'merchant_number', 'billing_country'],\n",
    "    ['payment_service_id', 'merchant_number', 'payment_currency'],\n",
    "    ['payment_service_id', 'billing_country','payment_currency'],\n",
    "    ['bin', 'is_expired'],\n",
    "    ['bank_name', 'is_expired'],\n",
    "    ['payment_service_id', 'is_expired'],\n",
    "    ['days_between', 'failed_decline_type'],\n",
    "    ['days_between', 'renewal_window'],\n",
    "    ['days_between', 'funding_source'],\n",
    "    ['card_brand', 'is_expired'],\n",
    "    ['sub_age_group', 'sub_duration_group'],\n",
    "    ['sub_duration_group', 'is_expired'],\n",
    "    ['segment_num_group', 'is_expired'],\n",
    "    ['day_of_week', 'billing_country'],\n",
    "    ['issuer_country', 'is_expired'] \n",
    "]\n",
    "\n",
    "features_encoded = features_cat_encoded + features_num_encoded\n",
    "\n",
    "additional_fields = [\n",
    "    'card_brand',  \n",
    "    'segment_num', \n",
    "    'segment_num_group',\n",
    "    'bank_name', \n",
    "    'duration', \n",
    "    'is_expired', \n",
    "    'renewal_window', \n",
    "    'payment_currency', \n",
    "    'funding_source', \n",
    "    'card_category', \n",
    "    'card_class', \n",
    "    'card_usage', \n",
    "    'renew_att_num', \n",
    "    'site_id', \n",
    "    'bin', \n",
    "    'merchant_number', \n",
    "    'billing_country', \n",
    "    'funding_source', \n",
    "    \"payment_service_id\", \n",
    "    'day_of_month', \n",
    "    'failed_decline_type',  \n",
    "    'failed_day_of_month', \n",
    "    'failed_response_code', \n",
    "    'payment_amount_usd', \n",
    "    'issuer_country',  \n",
    "    'failed_response_message',\n",
    "    'days_between',  \n",
    "    'transaction_date_in_string', \n",
    "    'cc_expiration_date', \n",
    "    'failed_attempt_date'\n",
    "]\n",
    "\n",
    "feature_candidates = ['card_brand', 'funding_source', 'card_category', 'card_class', 'card_usage', 'issuer_country', \n",
    "                 'day_of_month', 'site_id', 'failed_decline_type', 'merchant_number', \n",
    "                'payment_service_id', 'payment_method_id', 'bin', 'renew_att_num', 'failed_day_of_month', \n",
    "                'payment_currency', 'days_between', 'failed_response_code', 'payment_amount_usd', 'date_increment', \n",
    "                'transaction_hour', 'failed_response_messages_from_previous_cal', 'failed_response_codes_from_previous_cal', \n",
    "                'failed_decline_type_from_previous_cal', 'failed_response_messages_from_first_cal', 'failed_decline_type_from_first_cal', 'days_between_from_first_cal' ]\n",
    "\n",
    "usecols = feature_candidates +  ['new_status','subscription_id', 'subsegment_id', 'success', 'cid' ,'bank_name','added_expiry_years', 'failed_response_message','date_increment', 'received_date', 'billing_country', 'transaction_date_in_string', 'cc_expiration_date', 'failed_attempt_date']\n",
    "\n",
    "'''\n",
    "data parameters\n",
    "'''\n",
    "excluded_processors = ['mes', 'paypalExpress']\n",
    "subs_creation_date_files = [\n",
    "     'subs_subscription_creation_date_2017_01_2017_12.csv', \n",
    "     'subs_subscription_creation_date_2018_01_2018_05.csv',\n",
    "     'subs_subscription_creation_date_2018_06_2018_12.csv',\n",
    "     'subs_subscription_creation_date_2019_01_2019_12.csv', \n",
    "     'subs_subscription_creation_date_2020_01_2020_03.csv',\n",
    "     'subs_subscription_creation_date_2020_04.csv'\n",
    "]\n",
    "\n",
    "subs_files = [\n",
    "    'subs_subscription_2018_12_to_2020_01.csv', \n",
    "    'subs_li_item_2020_02_to_2020_02_20.csv',  \n",
    "    'subs_li_item_2020_03_2020_05.csv'\n",
    "]\n",
    "\n",
    "sub_seg_expire_files = [\n",
    "    'sub_seg_expire_2019_all.csv', \n",
    "    'sub_seg_expire_2020_01_2020_02.csv', \n",
    "    'sub_seg_expire_2020_03_to_2020_04.csv', \n",
    "    'sub_seg_expire_2020_05_2020_08.csv'\n",
    "]\n",
    "\n",
    "#'dca_2019_06.csv', 'dca_2019_07.csv', 'dca_2019_08.csv', 'dca_2019_09.csv','dca_2019_10.csv'\n",
    "# TO DO : dca_2019_11\n",
    "training_files = ['dca_2019_12.csv', \n",
    "                  'dca_2020_01.csv', 'dca_2020_02.csv']\n",
    "eval_files = [ 'dca_2020_03.csv']\n",
    "test_files = [ 'dca_2020_04.csv']\n",
    "bin_profile_per_date_month_path = 'bin_profile_per_date_month_2018_2020_03.csv'\n",
    "bank_profile_per_date_month_path = 'bank_profile_per_date_month_2018_2020_03.csv'\n",
    "bin_profile_per_day_of_month_path = 'bin_profile_per_date_month_2018_2020_03.csv'\n",
    "bank_profile_per_day_of_month_path = 'bank_profile_per_day_of_month_2018_2020_03.csv'\n",
    "\n",
    "\n",
    "'''\n",
    "training hyperparameters\n",
    "'''\n",
    "scale_pos_weight = None\n",
    "\n",
    "tuned_parameters = {}\n",
    "\n",
    "best_parameters = {\n",
    "              'depth': 5,\n",
    "              'iterations': 1201,\n",
    "              'random_seed': 7,\n",
    "              'scale_pos_weight': scale_pos_weight,\n",
    "              'subsample': 0.5,\n",
    "              'bagging_temperature': 3.5,\n",
    "              'rsm': 0.35,\n",
    "              'eval_metric': 'BrierScore',\n",
    "              'early_stopping_rounds': 500,\n",
    "              'model_size_reg': 2.5,\n",
    "              'l2_leaf_reg': 20.9,\n",
    "              'random_strength': 5.0\n",
    "              }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.web.utils import to_date\n",
    "from src.web.utils import days_between\n",
    "from src.web.utils import is_expired\n",
    "\n",
    "\n",
    "def days_between_period(df):\n",
    "    d1 = to_date(df['next_renewal_date'])\n",
    "    d2 = to_date(df['grace_period_date'])\n",
    "    return abs((d2 - d1).days)\n",
    "\n",
    "def process_dca_data(dca_df, df_sub, df_sub_seg, df_creation_date):\n",
    "    df = dca_df.copy()\n",
    "    \n",
    "    df_amex = df[(df.payment_service_id == 'mes') & (df.card_brand.isin(['American Express', 'Discover']))] \n",
    "\n",
    "    df = df\n",
    "    df = df[~(df['new_status'] == 'Reversed')]\n",
    "    \n",
    "    df = df[~(df.payment_service_id.isin(excluded_processors))]\n",
    "    df = df[~df['payment_amount_usd'].isna()]\n",
    "    df = pd.merge(df, df_sub[['subsegment_id', 'renewal_window', 'grace_period_date', 'next_renewal_date']], left_on='subsegment_id', right_on='subsegment_id', how='left')\n",
    "\n",
    "    df = pd.merge(df, df_sub_seg[['subsegment_id', 'duration', 'segment_num']], left_on='subsegment_id', right_on='subsegment_id', how='left')\n",
    "\n",
    "    \n",
    "    df['is_expired'] = df.apply(is_expired, axis=1)\n",
    "    df.loc[~df['date_increment'].isna(), 'is_expired'] = True\n",
    "\n",
    "    df = df[~(df.duration.isna())]\n",
    "    df = df[~(df['bin'] == 'nan')]\n",
    "    df = df[~(df['cc_expiration_date'] == 'nan')]\n",
    "    \n",
    "    df = pd.concat([df, df_amex])\n",
    "    df = pd.merge(df, df_creation_date, left_on='subscription_id', right_on='subscription_id', how='left')\n",
    "    df.subs_activation_date.fillna('2017-01-01 00:00:00', inplace=True)\n",
    "    df['sub_age'] = df.apply(lambda x: days_between(x.transaction_date_in_string, x.subs_activation_date), axis=1)\n",
    "\n",
    "    df = df.rename(columns={\"next_renewal_date\": \"first_calendar_attempt_date\"})\n",
    "    \n",
    "    df.failed_decline_type = df.failed_decline_type_from_previous_cal \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46751635, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subs_creation_date =  pd.concat((read_from(file, s3_dir='ml_files') for file in subs_creation_date_files) , ignore_index=True)\n",
    "subs_creation_date = subs_creation_date.rename(columns={\"SUBSCRIPTION_ID\": \"subscription_id\", \"CREATION_DATE\": \"subs_activation_date\"})\n",
    "subs_creation_date.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>grace_period_date</th>\n",
       "      <th>line_item_type</th>\n",
       "      <th>next_renewal_date</th>\n",
       "      <th>renewal_window</th>\n",
       "      <th>segment_number</th>\n",
       "      <th>subsegment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>RENEWED</td>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17904709400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>RENEWED</td>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17958051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>RENEWED</td>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17795605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>RENEWED</td>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14777236400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-20</td>\n",
       "      <td>RENEWED</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15218507800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 grace_period_date line_item_type next_renewal_date  \\\n",
       "0         NaN        2018-12-26        RENEWED        2018-12-15   \n",
       "1         NaN        2019-01-19        RENEWED        2018-12-20   \n",
       "2         NaN        2019-01-03        RENEWED        2018-12-04   \n",
       "3         NaN        2018-12-19        RENEWED        2018-12-04   \n",
       "4         NaN        2019-02-20        RENEWED        2019-01-27   \n",
       "\n",
       "   renewal_window  segment_number  subsegment_id  \n",
       "0              11             8.0    17904709400  \n",
       "1              30             2.0    17958051000  \n",
       "2              30             7.0    17795605900  \n",
       "3              15             NaN    14777236400  \n",
       "4              24             NaN    15218507800  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_subs =  pd.concat((read_from(file, s3_dir='training_files') for file in subs_files) , ignore_index=True)\n",
    "\n",
    "df_subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_sub_seg_expire =  pd.concat((read_from(file) for file in sub_seg_expire_files) , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py:228: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  copy=copy, sort=sort)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2126462, 48)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train = pd.concat((read_from(file, usecols=usecols, s3_dir='ml_files') for file in training_files) , ignore_index=True)\n",
    "df_train = process_dca_data(df_train, df_subs, df_sub_seg_expire, subs_creation_date)\n",
    "\n",
    "# df_train_2 = read_from('retry_success_2020_01_to_2020_02.csv', usecols=usecols, s3_dir='ml_files')\n",
    "# df_train_2 = df_train_2[(df_train_2.received_date >= '2020-02-01')]\n",
    "# df_train_2 = process_dca_data(df_train_2, df_subs, df_sub_seg_expire, subs_creation_date)\n",
    "# df_train = pd.concat([df_train, df_train_2])\n",
    "\n",
    "df_train.shape #(6543250, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(671071, 48)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.concat((read_from(file, usecols=usecols, s3_dir='ml_files') for file in eval_files) , ignore_index=True)\n",
    "\n",
    "# df_val = read_from(eval_file, usecols=usecols, s3_dir='ml_files')\n",
    "# df_val = df_val[(df_val.received_date >= '2020-03-01')]\n",
    "df_val = process_dca_data(df_val, df_subs, df_sub_seg_expire, subs_creation_date)\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(610289, 48)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_test = pd.concat((read_from(file, usecols=usecols, s3_dir='ml_files') for file in test_files) , ignore_index=True)\n",
    "\n",
    "# df_test = read_from(test_file, usecols=usecols, s3_dir='ml_files')\n",
    "\n",
    "# df_test = df_test[(df_test.received_date >= '2020-04-01')]\n",
    "df_test = process_dca_data(df_test, df_subs, df_sub_seg_expire, subs_creation_date)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import for training\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from spark_sklearn import GridSearchCV\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "# from src.web.utils import PreProcessing\n",
    "from src.web.preprocessing import PreProcessing\n",
    "from src.web.encoder import EnhancedLeaveOneOutEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_profile_per_date_month = read_from(bin_profile_per_date_month_path)\n",
    "\n",
    "bin_profile_per_date_month['bin'] = bin_profile_per_date_month['bin'].apply(str).str.replace('.0', '', regex=False)\n",
    "max_per_date_month_dict = bin_profile_per_date_month.set_index(['bin', 'month', 'day_of_month'])['Max_99'].T.to_dict()\n",
    "\n",
    "bin_profile_per_day_of_month = read_from(bin_profile_per_day_of_month_path)\n",
    "\n",
    "bin_profile_per_day_of_month['bin'] = bin_profile_per_day_of_month['bin'].apply(str).str.replace('.0', '', regex=False)\n",
    "max_per_day_of_month_dict = bin_profile_per_day_of_month.set_index(['bin', 'day_of_month'])['Max_99'].T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_profile_per_date_month = read_from(bank_profile_per_date_month_path)\n",
    "max_per_bank_card_date_month_dict = bank_profile_per_date_month.set_index(['bank_name', 'card_category', 'month', 'day_of_month'])['Max_99'].T.to_dict()\n",
    "\n",
    "bank_profile_per_day_of_month = read_from(bank_profile_per_day_of_month_path)\n",
    "max_per_bank_card_day_of_month_dict = bank_profile_per_day_of_month.set_index(['bank_name', 'card_category', 'day_of_month'])['Max_99'].T.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_per_date_month_dict = bin_profile_per_date_month.set_index(['bin', 'month', 'day_of_month'])['count'].T.to_dict()\n",
    "success_per_day_of_month_dict = bin_profile_per_day_of_month.set_index(['bin', 'day_of_month'])['count'].T.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126462, 48)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = len(df_train)\n",
    "balanced_size = len(df_train)\n",
    "fail_size = df_train[label].value_counts(normalize=True)[0.0]\n",
    "success_size =  df_train[label].value_counts(normalize=True)[1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segment_num_group = [0, 2, 3, 4, 5, 6, 7, 8, 15, 20, 25, 30, 40, 50, 70, 100, 150]\n",
    "\n",
    "df_train['segment_num_group'] = pd.cut(df_train['segment_num'], segment_num_group).astype(str).str.replace('.0', '', regex=False)\n",
    "df_val['segment_num_group'] = pd.cut(df_val['segment_num'], segment_num_group).astype(str).str.replace('.0', '', regex=False)\n",
    "df_test['segment_num_group'] = pd.cut(df_test['segment_num'], segment_num_group).astype(str).str.replace('.0', '', regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[(df_train['duration'] == 28) | (df_train['duration'] == 29) | (df_train['duration'] == 31) , 'duration'] = 30\n",
    "df_train.loc[(df_train['duration'] == 366) , 'duration'] = 365\n",
    "df_train.loc[(df_train['duration'] == 731) , 'duration'] = 730\n",
    "\n",
    "df_val.loc[(df_val['duration'] == 28) | (df_val['duration'] == 29) | (df_val['duration'] == 31) , 'duration'] = 30\n",
    "df_val.loc[(df_val['duration'] == 366) , 'duration'] = 365\n",
    "df_val.loc[(df_val['duration'] == 731) , 'duration'] = 730\n",
    "\n",
    "df_test.loc[(df_test['duration'] == 28) | (df_test['duration'] == 29) | (df_test['duration'] == 31) , 'duration'] = 30\n",
    "df_test.loc[df_test['duration'] == 366 , 'duration'] = 365\n",
    "df_test.loc[(df_test['duration'] == 731) , 'duration'] = 730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_group = [0, 3, 6, 9, 13, 17, 20, 25, 27, 33, 39, 43, 62, 70, 80, 88, 94, 100, 118, 125, 130, 146, 155, 176, 184, 200, 213, 230, 263, 300, 363, 368, 373,729, 733, 1000, 2000]\n",
    "\n",
    "df_train['sub_duration_group'] = pd.cut(df_train['duration'], duration_group).astype(str).str.replace('.0', '', regex=False) \n",
    "df_val['sub_duration_group'] = pd.cut(df_val['duration'], duration_group).astype(str).str.replace('.0', '', regex=False) \n",
    "df_test['sub_duration_group'] = pd.cut(df_test['duration'], duration_group).astype(str).str.replace('.0', '', regex=False) \n",
    "\n",
    "df_train['sub_age_group'] = pd.cut(df_train['sub_age'], duration_group).astype(str).str.replace('.0', '', regex=False) \n",
    "df_val['sub_age_group'] = pd.cut(df_val['sub_age'], duration_group).astype(str).str.replace('.0', '', regex=False) \n",
    "df_test['sub_age_group'] = pd.cut(df_test['sub_age'], duration_group).astype(str).str.replace('.0', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# from spark_sklearn import GridSearchCV\n",
    "\n",
    "from src.web.preprocessing import PreProcessing\n",
    "from src.web.preprocessing import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "# additional_fields = ['card_brand',  'segment_num', 'segment_num_group' ,'bank_name', 'duration', 'is_expired', 'renewal_window', 'payment_currency', 'funding_source', 'card_category', 'card_class', 'card_usage', 'renew_att_num', 'site_id', 'bin', 'merchant_number', 'billing_country', 'funding_source', \"payment_service_id\", 'day_of_month', 'failed_decline_type',  'failed_day_of_month', 'failed_response_code', 'payment_amount_usd', 'issuer_country',  'failed_response_message','days_between',  'transaction_date_in_string', 'cc_expiration_date', 'failed_attempt_date']\n",
    "additional_fields = [x for x in additional_fields if x not in (features_cat+features_num)]\n",
    "fields = features_cat + features_num + additional_fields\n",
    "\n",
    "\n",
    "\n",
    "features_dict = {'LABEL': label, 'FIELDS': fields ,'FEATURES_CAT': features_cat, 'FEATURES_NUM':features_num, 'FEATURES_ENCODED':features_encoded, 'FEATURES_NUM_ENCODED':features_num_encoded, 'FEATURES_NUM_CALCULATED':features_num_calculated, 'FEATURES_FLOAT': features_float}\n",
    "features_dict_key = 'preprocessing__features_dict'\n",
    "features_dict['df_bin_profile'] = None \n",
    "features_dict['df_decline_type'] = None\n",
    "\n",
    "features_dict['FEATURES_NUM_BIN_PROFILE'] = features_num_bin_profile\n",
    "features_dict['FEATURES_GROUPED'] = features_grouped\n",
    "features_dict['ADDITIONAL_FIELDS'] = additional_fields\n",
    "\n",
    "\n",
    "features_dict['group_dict'] = {\"max_per_date_month_dict\": max_per_date_month_dict, \"max_per_day_of_month_dict\": max_per_day_of_month_dict, \\\n",
    "                               \"max_per_bank_card_date_month_dict\": max_per_bank_card_date_month_dict, \"max_per_bank_card_day_of_month_dict\": max_per_bank_card_day_of_month_dict, \\\n",
    "                              \"success_per_date_month_dict\": success_per_date_month_dict, \"success_per_day_of_month_dict\": success_per_day_of_month_dict}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.features_encoded: ['month', 'days_between', 'renew_att_num', 'day_of_week', 'num_of_days', 'payment_service_id', 'merchant_number', 'month', 'is_expired', 'segment_num_group', 'sub_duration_group', 'sub_age_group', 'card_brand']\n",
      "# Finish handle_feat_encoded.\n",
      "self.features_all:  None\n",
      "In fit, self.features_cat: ['failed_response_code', 'failed_decline_type', 'day_of_month', 'funding_source', 'payment_currency', 'days_between', 'billing_country', 'renewal_window', 'renew_att_num', 'card_brand']\n",
      "['failed_response_code', 'failed_decline_type', 'day_of_month', 'funding_source', 'payment_currency', 'days_between', 'billing_country', 'renewal_window', 'renew_att_num', 'card_brand']\n",
      "# not using cat encoder\n",
      "# Finish handle_feat_encoded.\n",
      "# transform_time: 1.5084774494171143\n",
      "  failed_response_code failed_decline_type day_of_month funding_source  \\\n",
      "0                  806                base            5         credit   \n",
      "1                  806                base           12         credit   \n",
      "2                  806                base           19         credit   \n",
      "3                  806                base           21         credit   \n",
      "4                  521   insufficientfunds            3          debit   \n",
      "\n",
      "  payment_currency days_between billing_country renewal_window renew_att_num  \\\n",
      "0              hkd            7              hk             30             3   \n",
      "1              hkd            7              hk             30             4   \n",
      "2              hkd            7              hk             30             5   \n",
      "3              hkd            2              hk             30             6   \n",
      "4              usd            7              cr             30             2   \n",
      "\n",
      "  card_brand payment_service_id-merchant_number-billing_country  \\\n",
      "0       visa              netgiro-bms-1411163460-hkd-pacific-hk   \n",
      "1       visa              netgiro-bms-1411163460-hkd-pacific-hk   \n",
      "2       visa              netgiro-bms-1411163460-hkd-pacific-hk   \n",
      "3       visa              netgiro-bms-1411163460-hkd-pacific-hk   \n",
      "4       visa                            adyen-dr_ireland_row-cr   \n",
      "\n",
      "  payment_service_id-merchant_number-payment_currency  \\\n",
      "0              netgiro-bms-1411163460-hkd-pacific-hkd   \n",
      "1              netgiro-bms-1411163460-hkd-pacific-hkd   \n",
      "2              netgiro-bms-1411163460-hkd-pacific-hkd   \n",
      "3              netgiro-bms-1411163460-hkd-pacific-hkd   \n",
      "4                            adyen-dr_ireland_row-usd   \n",
      "\n",
      "  payment_service_id-billing_country-payment_currency bin-is_expired  \\\n",
      "0                                  netgiro-bms-hk-hkd   467932-false   \n",
      "1                                  netgiro-bms-hk-hkd   467932-false   \n",
      "2                                  netgiro-bms-hk-hkd   467932-false   \n",
      "3                                  netgiro-bms-hk-hkd   467932-false   \n",
      "4                                        adyen-cr-usd   415277-false   \n",
      "\n",
      "                                    bank_name-is_expired  \\\n",
      "0  thehongkongandshanghaibankingcorporationlimited-false   \n",
      "1  thehongkongandshanghaibankingcorporationlimited-false   \n",
      "2  thehongkongandshanghaibankingcorporationlimited-false   \n",
      "3  thehongkongandshanghaibankingcorporationlimited-false   \n",
      "4                                 bancodecostarica-false   \n",
      "\n",
      "  payment_service_id-is_expired days_between-failed_decline_type  \\\n",
      "0             netgiro-bms-false                           7-base   \n",
      "1             netgiro-bms-false                           7-base   \n",
      "2             netgiro-bms-false                           7-base   \n",
      "3             netgiro-bms-false                           2-base   \n",
      "4                   adyen-false              7-insufficientfunds   \n",
      "\n",
      "  days_between-renewal_window days_between-funding_source  \\\n",
      "0                        7-30                    7-credit   \n",
      "1                        7-30                    7-credit   \n",
      "2                        7-30                    7-credit   \n",
      "3                        2-30                    2-credit   \n",
      "4                        7-30                     7-debit   \n",
      "\n",
      "  card_brand-is_expired sub_age_group-sub_duration_group  \\\n",
      "0            visa-false              (1000,2000]-(27,33]   \n",
      "1            visa-false              (1000,2000]-(27,33]   \n",
      "2            visa-false              (1000,2000]-(27,33]   \n",
      "3            visa-false              (1000,2000]-(27,33]   \n",
      "4            visa-false              (1000,2000]-(27,33]   \n",
      "\n",
      "  sub_duration_group-is_expired segment_num_group-is_expired  \\\n",
      "0                 (27,33]-false                (30,40]-false   \n",
      "1                 (27,33]-false                (30,40]-false   \n",
      "2                 (27,33]-false                (30,40]-false   \n",
      "3                 (27,33]-false                (30,40]-false   \n",
      "4                 (27,33]-false                (30,40]-false   \n",
      "\n",
      "  day_of_week-billing_country issuer_country-is_expired  duration  sub_age  \n",
      "0                        4-hk                  HK-false      -1.0   1050.0  \n",
      "1                        4-hk                  HK-false      -1.0   1057.0  \n",
      "2                        4-hk                  HK-false      -1.0   1064.0  \n",
      "3                        6-hk                  HK-false      -1.0   1066.0  \n",
      "4                        2-cr                  CR-false      -1.0   1043.0  \n"
     ]
    }
   ],
   "source": [
    "'''Prepares training parameters'''\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import src.web.preprocessing\n",
    "from src.web.preprocessing import PreProcessing\n",
    "from src.web.train_util import *\n",
    "from importlib import import_module\n",
    "import sys\n",
    "\n",
    "classifier = CatBoostClassifier\n",
    "\n",
    "cat_features_len = len(features_cat) +  len (features_grouped)\n",
    "input_data = df_train\n",
    "\n",
    "features_dict['use_cat_encoder'] = False\n",
    "_preProcessor = PreProcessing().fit(input_data, input_data['success'], features_dict=features_dict)\n",
    "\n",
    "_df_val = df_val \n",
    "_df_test = df_test\n",
    "scale_pos_weight = (_df_val[label].value_counts(normalize=True)[0.0] / _df_val[label].value_counts(normalize=True)[1.0] )\n",
    "best_parameters['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "_x_eval = _preProcessor.transform(_df_val)\n",
    "_y_eval = _df_val[\"success\"]\n",
    "\n",
    "\n",
    "alg_name = 'catboostclassifier'\n",
    "\n",
    "\n",
    "model_file = ''\n",
    "\n",
    "\n",
    "cat_features = list(range(0,cat_features_len))\n",
    "\n",
    "fit_params = {\n",
    "    f\"{alg_name}__verbose\": True,\n",
    "    f\"{alg_name}__cat_features\": cat_features,\n",
    "    f\"{alg_name}__plot\": True,\n",
    "    f\"{alg_name}__eval_set\": Pool(_x_eval, _y_eval, cat_features)\n",
    "}\n",
    "\n",
    "\n",
    "features_dict['fit_params'] = fit_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_runner =  None\n",
      "project_id = None\n",
      "training_id = None\n",
      "metrics_feedback_url = None\n",
      "model_destination = None\n",
      "label = success\n",
      "training_data = \n",
      "training_files = ['dca_2019_12.csv', 'dca_2020_01.csv', 'dca_2020_02.csv']\n",
      "eval_files = ['dca_2020_03.csv']\n",
      "test_files = ['dca_2020_04.csv']\n",
      "sub_seg_expire_files = ['sub_seg_expire_2019_all.csv', 'sub_seg_expire_2020_01_2020_02.csv', 'sub_seg_expire_2020_03_to_2020_04.csv', 'sub_seg_expire_2020_05_2020_08.csv']\n",
      "subs_files = ['subs_subscription_2018_12_to_2020_01.csv', 'subs_li_item_2020_02_to_2020_02_20.csv', 'subs_li_item_2020_03_2020_05.csv']\n",
      "subs_creation_date_files = ['subs_subscription_creation_date_2017_01_2017_12.csv', 'subs_subscription_creation_date_2018_01_2018_05.csv', 'subs_subscription_creation_date_2018_06_2018_12.csv', 'subs_subscription_creation_date_2019_01_2019_12.csv', 'subs_subscription_creation_date_2020_01_2020_03.csv', 'subs_subscription_creation_date_2020_04.csv']\n",
      "excluded_processors = ['mes', 'paypalExpress']\n",
      "\n",
      "============== training parameters & features ================ \n",
      "input_features = {'billing_country': {'type': 'string'}, 'bin': {'type': 'string'}, 'card_brand': {'type': 'string'}, 'card_category': {'type': 'string'}, 'card_class': {'type': 'string'}, 'card_usage': {'type': 'string'}, 'cc_expiration_date': {'type': 'string'}, 'day_of_month': {'type': 'integer'}, 'failed_attempt_date': {'type': 'string'}, 'failed_response_code': {'type': 'string'}, 'failed_response_message': {'type': 'string'}, 'funding_source': {'type': 'string'}, 'issuer_country': {'type': 'string'}, 'merchant_number': {'type': 'string'}, 'payment_amount_usd': {'type': 'number'}, 'payment_currency': {'type': 'string'}, 'payment_method_id': {'type': 'string'}, 'payment_service_id': {'type': 'string'}, 'renew_att_num': {'type': 'integer'}, 'site_id': {'type': 'string'}, 'transaction_date_in_string': {'type': 'string'}, 'renewal_window': {'type': 'integer'}, 'duration': {'type': 'integer'}, 'segment_num': {'type': 'integer'}, 'sub_age': {'type': 'integer'}, 'bank_name': {'type': 'string'}, 'first_calendar_attempt_date': {'type': 'string'}}\n",
      "additional_fields = ['segment_num', 'segment_num_group', 'bank_name', 'is_expired', 'card_category', 'card_class', 'card_usage', 'site_id', 'bin', 'merchant_number', 'payment_service_id', 'failed_day_of_month', 'payment_amount_usd', 'issuer_country', 'failed_response_message', 'transaction_date_in_string', 'cc_expiration_date', 'failed_attempt_date']\n",
      "tuned_parameters = {}\n",
      "best_parameters = {'depth': 5, 'iterations': 1201, 'random_seed': 7, 'scale_pos_weight': 9.356353591160222, 'subsample': 0.5, 'bagging_temperature': 3.5, 'rsm': 0.35, 'eval_metric': 'BrierScore', 'early_stopping_rounds': 500, 'model_size_reg': 2.5, 'l2_leaf_reg': 20.9, 'random_strength': 5.0}\n",
      "features_cat = ['failed_response_code', 'failed_decline_type', 'day_of_month', 'funding_source', 'payment_currency', 'days_between', 'billing_country', 'renewal_window', 'renew_att_num', 'card_brand']\n",
      "features_float = ['bin', 'failed_response_code', 'date_increment', 'renewal_window']\n",
      "features_num = ['duration', 'sub_age']\n",
      "features_grouped = [['payment_service_id', 'merchant_number', 'billing_country'], ['payment_service_id', 'merchant_number', 'payment_currency'], ['payment_service_id', 'billing_country', 'payment_currency'], ['bin', 'is_expired'], ['bank_name', 'is_expired'], ['payment_service_id', 'is_expired'], ['days_between', 'failed_decline_type'], ['days_between', 'renewal_window'], ['days_between', 'funding_source'], ['card_brand', 'is_expired'], ['sub_age_group', 'sub_duration_group'], ['sub_duration_group', 'is_expired'], ['segment_num_group', 'is_expired'], ['day_of_week', 'billing_country'], ['issuer_country', 'is_expired']]\n",
      "feature_num_encoded = ['month', 'days_between', 'renew_att_num', 'day_of_week', 'num_of_days', 'payment_service_id', 'merchant_number', 'month', 'is_expired', 'segment_num_group', 'sub_duration_group', 'sub_age_group', 'card_brand']\n",
      "features_encoded = ['month', 'days_between', 'renew_att_num', 'day_of_week', 'num_of_days', 'payment_service_id', 'merchant_number', 'month', 'is_expired', 'segment_num_group', 'sub_duration_group', 'sub_age_group', 'card_brand']\n",
      "features_num_calculated = []\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "print out all parameters.\n",
    "'''\n",
    "\n",
    "print('training_runner = ', training_runner)\n",
    "print('project_id =', project_id)\n",
    "print('training_id =', training_id)\n",
    "print('metrics_feedback_url =', metrics_feedback_url)\n",
    "print('model_destination =', model_destination)\n",
    "print('label =', label)\n",
    "print('training_data =', training_data)\n",
    "\n",
    "print('training_files =', training_files)\n",
    "print('eval_files =', eval_files)\n",
    "print('test_files =', test_files)\n",
    "print('sub_seg_expire_files =', sub_seg_expire_files)\n",
    "print('subs_files =', subs_files)\n",
    "print('subs_creation_date_files =', subs_creation_date_files)\n",
    "print('excluded_processors =', excluded_processors)\n",
    "\n",
    "'''\n",
    "print out manipulated and aggregated features.\n",
    "'''\n",
    "print('\\n============== training parameters & features ================ ')\n",
    "print('input_features =', input_features)\n",
    "print('additional_fields =', additional_fields)\n",
    "print('tuned_parameters =', tuned_parameters)\n",
    "print('best_parameters =', best_parameters)\n",
    "print('features_cat =', features_cat)\n",
    "print('features_float =', features_float)\n",
    "print('features_num =', features_num)\n",
    "print('features_grouped =', features_grouped)\n",
    "\n",
    "print('feature_num_encoded =', features_encoded)\n",
    "print('features_encoded =', features_encoded)\n",
    "print('features_num_calculated =', features_num_calculated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Using assigned test_data\n",
      "--------------------\n",
      "(2126462, 30)\n",
      "(2126462,)\n",
      "(610289, 30)\n",
      "(610289,)\n",
      "Best Retry preprocessing pipeline ... \n",
      "using fit_params ....... \n",
      "In EnhancedPipeline fit_predict ...\n",
      "self.features_encoded: ['month', 'days_between', 'renew_att_num', 'day_of_week', 'num_of_days', 'payment_service_id', 'merchant_number', 'month', 'is_expired', 'segment_num_group', 'sub_duration_group', 'sub_age_group', 'card_brand']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:346: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[feat] = df[feat].fillna('').astype(str).str.replace('.0', '', regex=False)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:359: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[DAY_OF_WEEK] = df[TXN_DATE_IN_STR].apply(to_weekday)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[IS_WEEKEND] = df[DAY_OF_WEEK].apply(is_weekend)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:377: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[DAYS_BETWEEN] = df.apply(days_between_ds, axis=1)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:388: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['num_of_days'] = df[TXN_DATE_IN_STR].apply(num_of_days)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:394: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[MONTH] = df[TXN_DATE_IN_STR].apply(to_month)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:397: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['cc_expiration_date'] = df['cc_expiration_date'].apply(str)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:416: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['segment_num'] = df['segment_num'].astype(int)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:428: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['duration'] = df['duration'].astype(int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:438: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['sub_duration_group'] = pd.cut(df['duration'], duration_group).astype(str).str.replace('.0', '', regex=False)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:444: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['sub_age'] = df['sub_age'].astype(int)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:450: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['sub_age_group'] = pd.cut(df['sub_age'], duration_group).astype(str).str.replace('.0', '', regex=False)\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:466: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['bank_name'] = df[\"bank_name\"].astype(str).apply(lambda x: x.lower().replace(' ', '').replace(\"nationalassociation\", \"n.a\").replace(\",\", \"\"))\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:469: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['card_category'] = df[\"card_category\"].astype(str).apply(lambda x: x.lower().replace(' ', '').replace(\",\", \"\"))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Finish handle_feat_encoded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:488: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[BIN] = pd.to_numeric(df[BIN], errors='coerce')\n",
      "/var/spark/jupyter-notebooks/src/web/preprocessing.py:489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[BIN] = df[BIN].astype(str).str.replace('.0', '', regex=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.features_all:  None\n",
      "In fit, self.features_cat: ['failed_response_code', 'failed_decline_type', 'day_of_month', 'funding_source', 'payment_currency', 'days_between', 'billing_country', 'renewal_window', 'renew_att_num', 'card_brand']\n",
      "['failed_response_code', 'failed_decline_type', 'day_of_month', 'funding_source', 'payment_currency', 'days_between', 'billing_country', 'renewal_window', 'renew_att_num', 'card_brand']\n",
      "# not using cat encoder\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Train the model\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "clf, result_d = build_and_train(\n",
    "    input_data, \n",
    "    classifier, \n",
    "    tuned_parameters, \n",
    "    alg_name, \n",
    "    model_file, \n",
    "    best_param=best_parameters, \n",
    "    features_dict=features_dict, \n",
    "    test_data=_df_test,\n",
    "    metrics_feedback_url=metrics_feedback_url)\n",
    "                                   \n",
    "print(\"result_dict: \", result_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ML-BR-1 version 396 is inserted into model repo\n",
      "model_file generated:  ['/var/spark/ml_files/models/ML-BR-1.396.pkl']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "output the model\n",
    "'''\n",
    "start_date = '2019-12-01'\n",
    "end_date = '2020-02-01'\n",
    "if training_runner is None:\n",
    "    model_id = 'ML-BR-1'\n",
    "    version = get_latest_version(model_id, model_type) + 1\n",
    "    model_name = model_id + '.' + str(version)\n",
    "    model_file, model_file_name = write_model(clf, model_name)\n",
    "    \n",
    "    preprocess_repo_path = handle_preprocessing_file(model_id, version)\n",
    "    size_desc = str(\", original size: %s (fail: %s, success: %s), balanced_size: %s\" % (original_size, fail_size, success_size, original_size))\n",
    "    desc = 'Using more specific failed_decline_type. Remove site_id.  Remove days_between-card_brand and funding_source. Add days_between-failed_decline_code. Include data with null first_cal_attempt. Add bank_name-is_expired, handle card_brand to be lower when grouping. Remove days_between_first_cal. With days_between-card_brand, reduce model_size_reg. Handle sub_duration_group in preprocessing. Minus segment_num. Using updated bank_profile, bin_profile to end of March. Use duration, sub_age, segment_num as numeric. Update sub_duration_group, days_between-card_brand,  duration(handle 28, 29,31 366 and 731), card_brand, renew_att_num,  sub_age.  Add days_between-failed_decline_type.  bank_card_max_per_date.  Add issuer_country-is_expired and bin-is_expired .is_expired to be True for all non na date increment. More individual features. Add more specific failed_decline_type. 2020_03 as val data and 2020_04 as test data  {}_{}_for_calendar retry model,  eval_metric= BrierScore, with no date_increment, no payment amount and bin profile). {}'.format(start_date, end_date, size_desc)\n",
    "\n",
    "    hyper_params = result_d.pop('hyper_params', None)\n",
    "    extended_att = {\"preprocess_repo_path\": preprocess_repo_path, \"input_features\": input_features}\n",
    "    repo_path = upload_artifact(model_file_name)\n",
    "    insert_model_info(model_id, version, repo_path, desc=desc, model_type=model_type,eval_metrics=json.dumps(result_d), \n",
    "                      hyper_parameter=json.dumps(hyper_params), extended_att=json.dumps(extended_att), features_dict=features_dict, algorithm='CatBoostClassifier')\n",
    "    \n",
    "else:\n",
    "    model_file = joblib.dump(clf, model_destination)\n",
    "\n",
    "print('model_file generated: ', model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
